{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Look at the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Import Libraries](#chapter1)\n",
    "    * [Import magic autoreload](#section_1_1)\n",
    "    * [Import the libraries](#section_1_2)\n",
    "    * [Import custom functions.](#section_1_3)\n",
    "* [Read the Data](#chapter2)\n",
    "* [Inspect the Data](#chapter3)\n",
    "* [Create new variables](chapter4)\n",
    "* [Save the Data](#chapter5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries: <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the magic autoreload extension so that any changes in external python modules are automatically loaded. <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload 2\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries we will use in this notebook. <a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the current working directory to the project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/migue/OneDrive - NOVAIMS/Data Science/Coding Courses/Machine Learning II/Project\")\n",
    "# wd stands for working directory\n",
    "wd = os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import our custom functions. <a class=\"anchor\" id=\"section_1_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import funcs.py from the functions folder of the Project folder\n",
    "from functions.funcs import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data: <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the files in the directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataframe \u001b[94mBasket\u001b[0m for Customer Basket Dataset.csv\n",
      "Created dataframe \u001b[94mInfo\u001b[0m for Customer Info Dataset.csv\n",
      "Created dataframe \u001b[94mMapping\u001b[0m for Product Mapping Excel File.xlsx\n",
      "File Project Description and Info.pdf is not a .csv or .xlsx file. Skipping it.\n"
     ]
    }
   ],
   "source": [
    "dfs = load_dfs(wd + \"/prof_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframes from the csv files. <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created global variable Basket with values from dictionary dfs key Basket\n",
      "Created global variable Info with values from dictionary dfs key Info\n",
      "Created global variable Mapping with values from dictionary dfs key Mapping\n"
     ]
    }
   ],
   "source": [
    "# Create a global variable for each dataframe in the dfs dict\n",
    "for key in dfs.keys():\n",
    "    globals()[key] = dfs[key]\n",
    "    print(f\"Created global variable {key} with values from dictionary dfs key {key}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the data: <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mColumns in \u001b[94mBasket\u001b[0m\u001b[1m are: \u001b[0m\n",
      "\t-customer_id, invoice_id, list_of_goods\n",
      "\n",
      "\u001b[1mColumns in \u001b[94mInfo\u001b[0m\u001b[1m are: \u001b[0m\n",
      "\t-customer_id, customer_name, customer_gender, customer_birthdate, kids_home, \n",
      "\t-teens_home, number_complaints, distinct_stores_visited, lifetime_spend_groceries, lifetime_spend_electronics, \n",
      "\t-typical_hour, lifetime_spend_vegetables, lifetime_spend_nonalcohol_drinks, lifetime_spend_alcohol_drinks, lifetime_spend_meat, \n",
      "\t-lifetime_spend_fish, lifetime_spend_hygiene, lifetime_spend_videogames, lifetime_total_distinct_products, percentage_of_products_bought_promotion, \n",
      "\t-year_first_transaction, loyalty_card_number, latitude, longitude\n",
      "\n",
      "\u001b[1mColumns in \u001b[94mMapping\u001b[0m\u001b[1m are: \u001b[0m\n",
      "\t-product_name, category\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_cols(Basket, \"Basket\")\n",
    "print_cols(Info, \"Info\")\n",
    "print_cols(Mapping, \"Mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mBasket\u001b[0m has no missing values.\n",
      "\n",
      "In \u001b[94m\u001b[1mInfo\u001b[0m, the following columns have missing values:\n",
      "\t-Column \u001b[94mloyalty_card_number\u001b[0m has \u001b[91m24175\u001b[0m missing values. This equals \u001b[91m80.58%\u001b[0m of its values.\n",
      "\t\n",
      "\u001b[94m\u001b[1mMapping\u001b[0m has no missing values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_na_cols(Basket, \"Basket\")\n",
    "print_na_cols(Info, \"Info\")\n",
    "print_na_cols(Mapping, \"Mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in \u001b[94mBasket\u001b[0m: \u001b[91m0\u001b[0m\n",
      "Number of duplicates in \u001b[94mInfo\u001b[0m: \u001b[91m0\u001b[0m\n",
      "Number of duplicates in \u001b[94mMapping\u001b[0m: \u001b[91m1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "print(f\"Number of duplicates in {blue}Basket{end}: {red}{Basket.duplicated().sum()}{end}\")\n",
    "print(f\"Number of duplicates in {blue}Info{end}: {red}{Info.duplicated().sum()}{end}\")\n",
    "print(f\"Number of duplicates in {blue}Mapping{end}: {red}{Mapping.duplicated().sum()}{end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate customer_id in \u001b[94mInfo\u001b[0m: \u001b[91m0\u001b[0m\n",
      "Number of duplicate coordinates in \u001b[94mInfo\u001b[0m: \u001b[91m0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate customer_id in Info\n",
    "print(f\"Number of duplicate customer_id in {blue}Info{end}: {red}{Info.duplicated(subset='customer_id').sum()}{end}\")\n",
    "print(f\"Number of duplicate coordinates in {blue}Info{end}: {red}{Info.duplicated(subset=['latitude', 'longitude']).sum()}{end}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product_name    category\n",
      "128    asparagus  vegetables\n",
      "135    asparagus  vegetables\n"
     ]
    }
   ],
   "source": [
    "# print the duplicate rows in mapping with their index\n",
    "print(Mapping[Mapping.duplicated(keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In \u001b[94m\u001b[1mBasket\u001b[0m, the following columns have duplicate values:\n",
      "\t-Column \u001b[94mcustomer_id\u001b[0m has \u001b[91m69701\u001b[0m duplicate values. This equals \u001b[91m87.13%\u001b[0m of its values.\n",
      "\t-Column \u001b[94minvoice_id\u001b[0m has \u001b[91m251\u001b[0m duplicate values. This equals \u001b[91m0.31%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlist_of_goods\u001b[0m has \u001b[91m349\u001b[0m duplicate values. This equals \u001b[91m0.44%\u001b[0m of its values.\n",
      "\t\n",
      "In \u001b[94m\u001b[1mInfo\u001b[0m, the following columns have duplicate values:\n",
      "\t-Column \u001b[94mcustomer_name\u001b[0m has \u001b[91m557\u001b[0m duplicate values. This equals \u001b[91m1.86%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mcustomer_gender\u001b[0m has \u001b[91m29998\u001b[0m duplicate values. This equals \u001b[91m99.99%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mcustomer_birthdate\u001b[0m has \u001b[91m10\u001b[0m duplicate values. This equals \u001b[91m0.03%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mkids_home\u001b[0m has \u001b[91m29989\u001b[0m duplicate values. This equals \u001b[91m99.96%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mteens_home\u001b[0m has \u001b[91m29990\u001b[0m duplicate values. This equals \u001b[91m99.97%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mnumber_complaints\u001b[0m has \u001b[91m29990\u001b[0m duplicate values. This equals \u001b[91m99.97%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mdistinct_stores_visited\u001b[0m has \u001b[91m29986\u001b[0m duplicate values. This equals \u001b[91m99.95%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_groceries\u001b[0m has \u001b[91m23273\u001b[0m duplicate values. This equals \u001b[91m77.58%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_electronics\u001b[0m has \u001b[91m26705\u001b[0m duplicate values. This equals \u001b[91m89.02%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mtypical_hour\u001b[0m has \u001b[91m29953\u001b[0m duplicate values. This equals \u001b[91m99.84%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_vegetables\u001b[0m has \u001b[91m28646\u001b[0m duplicate values. This equals \u001b[91m95.49%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_nonalcohol_drinks\u001b[0m has \u001b[91m28424\u001b[0m duplicate values. This equals \u001b[91m94.75%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_alcohol_drinks\u001b[0m has \u001b[91m28792\u001b[0m duplicate values. This equals \u001b[91m95.97%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_meat\u001b[0m has \u001b[91m28203\u001b[0m duplicate values. This equals \u001b[91m94.01%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_fish\u001b[0m has \u001b[91m28200\u001b[0m duplicate values. This equals \u001b[91m94.0%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_hygiene\u001b[0m has \u001b[91m29157\u001b[0m duplicate values. This equals \u001b[91m97.19%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_videogames\u001b[0m has \u001b[91m28428\u001b[0m duplicate values. This equals \u001b[91m94.76%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_total_distinct_products\u001b[0m has \u001b[91m26827\u001b[0m duplicate values. This equals \u001b[91m89.42%\u001b[0m of its values.\n",
      "\t-Column \u001b[94myear_first_transaction\u001b[0m has \u001b[91m29968\u001b[0m duplicate values. This equals \u001b[91m99.89%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mloyalty_card_number\u001b[0m has \u001b[91m24333\u001b[0m duplicate values. This equals \u001b[91m81.11%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlongitude\u001b[0m has \u001b[91m857\u001b[0m duplicate values. This equals \u001b[91m2.86%\u001b[0m of its values.\n",
      "\t\n",
      "In \u001b[94m\u001b[1mMapping\u001b[0m, the following columns have duplicate values:\n",
      "\t-Column \u001b[94mproduct_name\u001b[0m has \u001b[91m2\u001b[0m duplicate values. This equals \u001b[91m1.22%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mcategory\u001b[0m has \u001b[91m155\u001b[0m duplicate values. This equals \u001b[91m94.51%\u001b[0m of its values.\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "print_dup_cols(Basket, \"Basket\")\n",
    "print_dup_cols(Info, \"Info\")\n",
    "print_dup_cols(Mapping, \"Mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mBasket\u001b[0m has no infinite values.\n",
      "\n",
      "In \u001b[94m\u001b[1mInfo\u001b[0m, the following columns have infinite values:\n",
      "\t-Column \u001b[94mtypical_hour\u001b[0m has \u001b[91m2\u001b[0m infinite values. This equals \u001b[91m0.01%\u001b[0m of its values.\n",
      "\t-Column \u001b[94mlifetime_spend_videogames\u001b[0m has \u001b[91m226\u001b[0m infinite values. This equals \u001b[91m0.75%\u001b[0m of its values.\n",
      "\t\n",
      "\u001b[94m\u001b[1mMapping\u001b[0m has no infinite values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_inf_cols(Basket, \"Basket\")\n",
    "print_inf_cols(Info, \"Info\")\n",
    "print_inf_cols(Mapping, \"Mapping\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the rows that have infinite values in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print rows that have inf values\n",
    "Info[Info.isin([np.inf, -np.inf]).any(axis = 1)].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the customers with infinite values appear to be supermarkets. Let's check the number of supermarkets in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of supermarkets in the dataset (rows that have supermarket in the customer_name)\n",
    "Info[Info.customer_name.str.contains(\"Supermarket\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the two dataframes to see if they are the same: \n",
    "Info[Info.customer_name.str.contains(\"Supermarket\")].equals(Info[Info.isin([np.inf, -np.inf]).any(axis = 1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that there are 226 supermarkets on the dataset and that these are the customers with infinite values. \n",
    "We will look into these customers in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarkets = Info[Info.customer_name.str.contains(\"Supermarket\")].customer_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarkets.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new variables <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "Using information in the dataset we can create new variables that might be useful for our analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the columns in the dataset with *lifetime_spend* in their name, we can create a new variable that represents the total amount of money they spent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with total amount spent by each customer by summing all lifetime_spent columns\n",
    "Info['lifetime_spent'] = Info[[col for col in Info.columns if 'lifetime_spend' in col]].sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new variable that represents the **total amount of money spent per year**. We can do this by dividing the total amount of money spent by the number of years they have been a customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables with the education level of the curstomers, None, Bsc, Msc and PhD. These will be 0, 1, 2 and 3 respectively.\n",
    "# The information regarding this is in the customer_name column of the Info dataframe\n",
    "Info['education_level'] = create_educ_level(Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18568\n",
       "1     3815\n",
       "3     3810\n",
       "2     3807\n",
       "Name: education_level, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info['education_level'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Data <a class=\"anchor\" id=\"chapter5\"></a>\n",
    "This saves the current state of the data to new csv files so that we can use them in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all three dataframes to csv files in a new folder named treated in the data folder of the project\n",
    "save_to_csv(dfs, wd + \"/data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
